-- MariaDB dump 10.17  Distrib 10.4.8-MariaDB, for Win64 (AMD64)
--
-- Host: localhost    Database: qna_list
-- ------------------------------------------------------
-- Server version	10.4.8-MariaDB

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `a_list`
--

DROP TABLE IF EXISTS `a_list`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `a_list` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `answer` longtext NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=26 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `a_list`
--

LOCK TABLES `a_list` WRITE;
/*!40000 ALTER TABLE `a_list` DISABLE KEYS */;
INSERT INTO `a_list` VALUES (1,'이 프로젝트는 AI 기반 Q&A 게시판 입니다.'),(2,'BERT라는 Google에서 개발한 인공지능 언어 모델입니다.'),(3,'sentencepiece로 문장을 토큰으로 나눕니다.'),(4,'답변 벡터값에 대한 벡터 분류를 통해 구분합니다.'),(5,'Bidirectional Encoder Representations from Transformers 입니다.'),(6,'단어와 그 단어의 주변에 있는 단어 그리고 단어의 위치를 종합하여 단어의 의미와 단어 사이의 의미관계를 이해하게 합니다.'),(7,'자기 자신을 참조하는 것을 막기 위해 각 단어에 마스크를 씌운 후 문맥을 파악하는 방식으로 각각의 단어에 대한 학습을 진행합니다'),(8,'단어의 앞 그리고 뒤에 존재하는 단어에서 단어의 의미를 추측하며 문장 사이의 관계를 학습하기 위하여 두 문장이 연결된 문장인지 확인하는 태스크를 통해 문장의 의미 또한 인식합니다.'),(9,'PyTorch를 사용합니다.'),(10,'단어의 토큰으로 기존 Word2vec같이 단어의 값을 의미합니다.'),(11,'각각의 문장마다 다른 벡터 값을 갖음으로써 각각의 문장을 구분할 수 있도록 해줍니다.'),(12,'문장의 위치에 따라서 주어진 벡터 값으로 한 문장에서 여러 번 다른 의미로 사용된 단어를 구분할 수 있도록 합니다.'),(13,'인코딩은 같은 단어라도 나온 위치와 문장에 따라서 다른 의미로 해석할 수 있게 되고, 더 효율적으로 문장의 의도를 인식 할 수 있도록 해줍니다.'),(14,'BERT는 여러 번 반복하여 의미를 분석하고 예측합니다.\r\n이 과정을 통하여 BERT 모델은 단어의 의미를 더 잘 파악하고, 단어 사이의 관계도 더 잘 이해하게 됩니다.\r\nBERT 학습 방법으로 feature-base와 fine-tuning이 있습니다\r\n'),(15,'Feature-base 방법은 특정 작업을 하기 위해 필요한 데이터를 학습하는 방법입니다.\r\nFeature-base는 기본 데이터가 충분할 경우 작업을 위해 최적화된 모델을 얻을 수 있습니다.\r\n하지만 학습을 위해 오랜 시간이 소요되며, 데이터가 충분이 많아야 합니다.'),(16,'Fine-tuning 방법은 작업을 범용적인 문장을 이용해서 학습하고, 이미 학습된 데이터를 이용하기 때문에 연산 소요를 감소시킬 수 있지만, 비교적 정확도가 떨어질 수 있으며 이 또한 지속적인 tuning을 하여 모델을 최적화 해야 합니다.\r\nFine-tuning 방법은 범용적인 데이터를 학습하거나 이미 학습된 데이터를 기본적으로 적용하며 그 위에 각 작업을 위한 데이터를 적용하여 모델을 최적화하는 방법이다.'),(17,'Google에서 개발한 문장을 토큰으로 나누는데 사용되는 기능을 제공하는 라이브러리입니다.\r\nBERT의 input은 토큰 형태의 데이터를 입력 받으므로 이를 이용하여 문장을 토큰화 하여 입력 값으로 사용할 수 있게 됩니다.'),(18,'이미 알려진 단어들 또는 구조들을 사용하여 문장을 단어 단위로 나누는 wordpiece와 달리 sentencepiece는 문장을 각각 유닛(글자) 단위로 나눈 후 주변 유닛과 병합하며 자주 사용되는 큰 유닛을 만들어 냅니다.\r\n이러한 방식으로 문장을 토큰화 시킬 경우 토크나이저는 각 언어에 대한 지식 없이 빈번히 등장하는 문자열을 찾고, 단어들을 최소한의 의미 단위로 나누어서 저장할 수 있도록 합니다.'),(19,'Facebook의 인공지능 연구팀에서 개발한 Python에서 사용 가능한 오픈소스 머신 러닝 라이브러리입니다.\r\n자연어 처리에 사용되며 GPU를 사용할 수 있기 때문에 빠른 속도로 데이터를 처리할 수 있습니다.\r\n또 다른 자연어 처리를 위한 라이브러리인 Tensorflow와 달리 직관적인 구조와 쉬운 난이도 덕분에 PyTorch 사용자가 늘고 있는 추세입니다.'),(20,'웹 서비스 게시판은 Docker를 이용한 마이크로서비스 형식으로 배포됩니다.\r\n게시판은 REST API 를 노출하며 ML 파트는 이 API 에 접근하여 필요한 모든 과정을 수행합니다.'),(21,'MySQL과 MariaDB를 사용합니다.'),(22,'김도현, 정유환, 정진호가 개발에 참여하였습니다.'),(23,'Docker는 매우 효율적인 가상화 애플리케이션으로 개별 애플리케이션 소프트웨어를 최소 의존성 및 기본적인 운영체제 라이브러리만을 탑재해 마치 하나의 가상 머신처럼 동작하게 만들어주는 서비스입니다.\r\n기존 기계어 단위의 가상화가 필요했던 솔루션들과는 달리 OS 레벨의 리소스 분리를 이용하여 동작하기 때문에 가상화의 부하가 매우 적다는 장점이 있습니다.'),(24,'WordPress 는 PHP 와 MySQL 로 만들어진 Content Management System 입니다.\r\nWordPress 는 방대한 플러그인 생태계와 템플릿 시스템을 갖추고 있어 확장성이 매우 용이합니다.\r\n보통의 경우 WordPress를 블로그나 쇼핑몰에 이용하는 경우가 많은데, 게시판 확장 역시 제공하고 있습니다.'),(25,'WordPress는 REST API 인터페이스를 제공하여 내부 구조를 알지 못하는 상태에서 질문 및 답변 글 게시의 자동화가 가능합니다.');
/*!40000 ALTER TABLE `a_list` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `q_list`
--

DROP TABLE IF EXISTS `q_list`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `q_list` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `question` text NOT NULL,
  `answer_no` int(10) unsigned DEFAULT NULL,
  `l_pt` int(11) NOT NULL DEFAULT 0,
  PRIMARY KEY (`id`),
  KEY `answer_no` (`answer_no`),
  CONSTRAINT `q_list_ibfk_1` FOREIGN KEY (`answer_no`) REFERENCES `a_list` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=192 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `q_list`
--

LOCK TABLES `q_list` WRITE;
/*!40000 ALTER TABLE `q_list` DISABLE KEYS */;
INSERT INTO `q_list` VALUES (1,'이 프로젝트의 이름은 무엇인가요?',1,0),(2,'이 프로젝트의 언어 모델은 무엇입니까?',2,0),(3,'문장을 어떻게 나누나요?',3,0),(4,'유사한 질문은 어떻게 구분하나요?',4,0),(5,'이 프로젝트는 무엇입니까?',1,0),(6,'이 작품의 주제는 뭔가요?',1,0),(7,'이건 무슨 내용인가요?',1,0),(8,'이 작품은 무엇인가요?',1,0),(9,'이 프로젝트는 무엇에 대해 다루나요?',1,0),(10,'이건 주제가 무엇인가요?',1,0),(11,'어떤 내용의 프로젝트입니까?',1,0),(12,'이 작품의 언어 모델은 무엇입니까?',2,0),(13,'해당 프로젝트의 인공지능 모델이 뭔가요?',2,0),(14,'사용하고있는 언어 모델에 대해 알려주세요',2,0),(15,'어떤 인공지능을 써서 자연어 처리를 합니까?',2,0),(16,'자연어 처리를 어떤 인공지능 모델로 처리하나요?',2,0),(17,'이건 어떤 언어 모델을 사용합니까?',2,0),(18,'자연어 처리 단계에서 문장 처리를 어떻게 합니까?',3,0),(19,'문장을 어떻게 토큰으로 나누나요?',3,0),(20,'문장에서 토큰을 어떻게 만드나요?',3,0),(21,'문장의 자연어 처리를 위해 무엇을 하나요?',3,0),(22,'문장 토큰을 만드는 기능이 뭔가요?',3,0),(23,'문장을 토큰화 하는데 어떤 기술을 쓰나요?',3,0),(24,'문장 토큰화를 어떤 방식으로 합니까?',3,0),(25,'비슷한 질문을 어떻게 처리하나요',4,0),(26,'질문이 거의 같으면 어떻게 하나요?',4,0),(27,'질문 유사도를 구분하는 방법이 무엇인가요?',4,0),(28,'비슷한 질문 구분 방법을 알려주세요',4,0),(29,'유사한 질문을 구분하는 방법이 뭔가요?',4,0),(30,'질문이 비슷비슷할 때 어떻게 합니까?',4,0),(31,'가까운 질문들을 어떤 방식으로 구분 짓나요?',4,0),(32,'BERT가 무슨 뜻입니까?',5,0),(33,'BERT는 무엇을 의미하나요?',5,0),(34,'BERT가 무슨 약자인지 알려주세요',5,0),(35,'BERT의 뜻 풀이를 가르쳐주세요',5,0),(36,'BERT를 풀어보면 무엇이 되나요?',5,0),(37,'어떻게 BERT가 된 건가요?',5,0),(38,'버트는 무엇을 의미합니까?',5,0),(39,'Transformer가 무엇입니까?',6,0),(40,'Transformer는 무엇인가요?',6,0),(41,'트랜스포머가 무엇인가요?',6,0),(42,'Transformer는 무슨 일을 하나요?',6,0),(43,'트랜스포머는 무엇입니까?',6,0),(44,'트랜스포머는 무슨 일을 하나요?',6,0),(45,'Transformer가 하는 일이 무엇입니까?',6,0),(46,'단어 자기자신을 참조할 수 있지 않나요?',7,0),(47,'그렇게 하면 그 단어도 참조하게 되지 않습니까?',7,0),(48,'현재 분석중인 단어도 참조하지 않나요?',7,0),(49,'자기 자신을 참조하는 문제는 어떻게 해결하나요?',7,0),(50,'단어 자신을 참조하는 경우를 어떻게 해결했나요?',7,0),(51,'현재 단어에 대한 참조를 하면 문제되지 않나요?',7,0),(52,'현재 단어를 참조하지 않게 하기 위해 어떤 방법을 쓰나요?',7,0),(53,'BERT는 어떤 방식으로 단어의 의미를 추측하나요?',8,0),(54,'BERT의 단어 의미 추측 방식을 알려주세요.',8,0),(55,'단어의 의미를 BERT가 어떻게 추측하나요?',8,0),(56,'BERT가 사용하는 단어 의미 추측 방법이 무엇인가요?',8,0),(57,'버트는 어떤 방법으로 단어의 의미를 학습하나요?',8,0),(58,'버트가 사용하는 단어 의미 추측 방법이 뭔가요?',8,0),(59,'단어의 의미를 버트가 어떻게 알아내나요?',8,0),(60,'버트의 단어 의미 추측 방법을 알려주세요',8,0),(61,'어떤 머신러닝 라이브러리를 사용하나요?',9,0),(62,'이 프로젝트에서 사용한 머신 러닝 라이브러리는 무엇인가요?',9,0),(63,'Tensorflow와 PyTorch 중 무엇을 썼나요?',9,0),(64,'Tensorflow를 썼나요 아니면 PyTorch를 썼나요?',9,0),(65,'오픈소스 머신 러닝 라이브러리들 중 무엇을 썼나요?',9,0),(66,'PyTorch와 Tensorflow중 무엇을 썼나요?',9,0),(67,'텐서플로와 파이토치 중 무엇을 썼나요?',9,0),(68,'파이토치와 텐서플로 중 무엇을 썼나요?',9,0),(69,'무슨 머신 러닝 라이브러리를 썼나요?',9,0),(70,'Token Embedding이 무엇인가요?',10,0),(71,'토큰 임베딩이 무엇인가요?',10,0),(72,'Token Embedding은 무엇을 의미하나요?',10,0),(73,'토큰 임베딩은 무엇을 의미하나요?',10,0),(74,'Embedding 중 Token Embedding이 무엇인가요?',10,0),(75,'임베딩 중 토큰 임베딩이 무엇인가요?',10,0),(76,'Token 임베딩에 대해 말해주세요',10,0),(77,'토큰 Embedding에 대해 알려주세요',10,0),(78,'Segment Embedding이 무엇인가요?',11,0),(79,'세그먼트 임베딩이 무엇인가요?',11,0),(80,'Segment Embedding은 무엇을 하나요?',11,0),(81,'세그먼트 임베딩은 무엇을 하나요?',11,0),(82,'Embedding 중 Segment Embedding이 무엇인가요?',11,0),(83,'임베딩 중 세그먼트 임베딩이 무엇인가요?',11,0),(84,'Segment 임베딩에 대해 말해주세요',11,0),(85,'세그먼트 Embedding에 대해 말해주세요',11,0),(86,'Position Embedding이 무엇인가요?',12,0),(87,'Position Embedding은 무엇을 하나요?',12,0),(88,'Embedding 중 Position Embedding이 무엇인가요?',12,0),(89,'Position 임베딩에 대해 말해주세요',12,0),(90,'포지션 임베딩이 무엇인가요?',12,0),(91,'포지션 Embedding에 대해 알려주세요.',12,0),(92,'포지션 임베딩은 무엇을 합니까?',12,0),(93,'임베딩 중 포지션 임베딩이 무엇입니까?',12,0),(94,'Encoding이 무엇입니까?',13,0),(95,'인코딩이 무엇인가요?',13,0),(96,'자연어 처리 단계 중 Encoding이 무엇입니까?',13,0),(97,'자연어 처리 단계 중 인코딩이 무엇인가요?',13,0),(98,'Encoding에 대해 알려주세요',13,0),(99,'인코딩에 대해 가르쳐주세요',13,0),(100,'Encoding 단계는 왜 필요합니까?',13,0),(101,'인코딩 단계가 필요한 이유가 무엇인가요?',13,0),(102,'BERT의 학습 방법은 어떤 것이 있나요?',14,0),(103,'BERT의 학습 방법으로 어느 것이 있습니까?',14,0),(104,'버트의 학습 방법은 어떻게 동작하나요?',14,0),(105,'BERT의 학습 방법을 알려주세요',14,0),(106,'버트의 학습 방식을 가르쳐주세요',14,0),(107,'어떤 방식으로 BERT는 학습합니까?',14,0),(108,'어떤 방식으로 버트는 학습하나요?',14,0),(109,'Feature-base 방법에 대해 설명해주세요',15,0),(110,'Feature-base 방법이 무엇입니까?',15,0),(111,'BERT의 Feature-base 방법은 어떤 방식인가요?',15,0),(112,'버트의 Feature-base 방법을 알려주세요',15,0),(113,'BERT가 쓰는 특징 기반 방법을 알려주세요',15,0),(114,'특징 기반 방법이 어떤 것 입니까?',15,0),(115,'버트의 특징 기반 방법이 무엇 입니까?',15,0),(116,'Fine-tuning 방법이 무엇인가요?',16,0),(117,'Fine-tuning 방법에 대해 알려주세요',16,0),(118,'BERT의 Fine-tuning 방법은 어떤 방식인가요?',16,0),(119,'버트의 Fine-tuning 방법을 가르쳐주세요',16,0),(120,'BERT가 사용하는 미세 조정 방법을 알려주세요',16,0),(121,'미세 조정 방법이 무엇 입니까?',16,0),(122,'버트의 미세 조정 방법은 어떤 것 입니까?',16,0),(123,'sentencepiece가 무엇입니까?',17,0),(124,'sentencepiece에 대해 알려주세요',17,0),(125,'센텐스피스가 무엇인가요?',17,0),(126,'센텐스피스는 무슨 라이브러리 인가요?',17,0),(127,'sentencepiece는 어떤 라이브러리 인가요?',17,0),(128,'자연어 처리에 사용한 라이브러리인 sentencepiece에 대해 알려주세요',17,0),(129,'센텐스피스라는 라이브러리가 무엇입니까?',17,0),(130,'sentencepiece는 무엇을 합니까?',17,0),(131,'sentencepiece와 wordpiece의 차이점이 무엇인가요?',18,0),(132,'sentencepiece와 wordpiece에 어떤 차이가 있습니까?',18,0),(133,'워드피스와 센텐스피스에 어떤 차이가 있습니까?',18,0),(134,'센텐스피스와 워드피스의 다른점을 알려주세요',18,0),(135,'센텐스피스랑 워드피스는 무슨 차이가 있나요?',18,0),(136,'wordpiece랑 sentencepiece에 어떤 차이가 있나요?',18,0),(137,'wordpiece랑 sentencepiece의 다른 부분을 가르쳐주세요',18,0),(138,'PyTorch가 무엇인가요',19,0),(139,'파이토치는 무슨 기능인가요',19,0),(140,'라이브러리 중 PyTorch에 대해 알려주세요',19,0),(141,'라이브러리 중 파이토치에 대해 가르쳐주세요',19,0),(142,'파이토치는 무슨 라이브러리 인가요?',19,0),(143,'PyTorch는 어디에 사용하는 라이브러리 인가요?',19,0),(144,'PyTorch에 대해 알려주세요',19,0),(145,'현재 사용 중인 라이브러리인 PyTorch에 대해 알려주세요',19,0),(146,'웹 서비스는 어떻게 구현했나요?',20,0),(147,'웹 사이트는 어떤 방식으로 만들었습니까?',20,0),(148,'웹 서비스 게시판은 어떻게 배포하고 정보를 공유합니까?',20,0),(149,'웹은 어떤 방식으로 배포하고 데이터를 전송합니까?',20,0),(150,'웹 서비스 구현 방식을 알려주세요',20,0),(151,'게시판 서비스는 어떻게 만들었나요?',20,0),(152,'게시판 서비스의 배포 및 데이터 통신 방법에 대해 가르쳐주세요.',20,0),(153,'자료 저장 방식으로 무엇을 쓰나요?',21,0),(154,'어떤 데이터베이스를 사용합니까?',21,0),(155,'이 프로젝트에 무슨 DB를 사용했나요?',21,0),(156,'이 프로젝트에 사용한 DBMS를 알려주세요',21,0),(157,'이 프로젝트에서 무슨 자료 저장 방식을 채택했나요?',21,0),(158,'무슨 DB를 사용하셨습니까?',21,0),(159,'사용한 데이터베이스에 무엇이 있나요?',21,0),(160,'무엇을 사용하여 자료들을 저장했나요?',21,0),(161,'이 프로젝트의 참여자를 알려주세요.',22,0),(162,'이 프로젝트는 누가 만들었나요?',22,0),(163,'제작 팀원들은 누가 있나요?',22,0),(164,'프로그램 개발 인원들은 누구입니까?',22,0),(165,'프로그램에 기여한 사람들이 누구인가요?',22,0),(166,'어떤 사람들이 이 프로젝트를 진행했습니까?',22,0),(167,'여기 있는 사람들의 이름이 무엇입니까?',22,0),(168,'개발자의 이름을 가르쳐줘요',22,0),(169,'Docker에 대해 알려주세요.',23,0),(170,'Docker가 무엇입니까?',23,0),(171,'도커는 어떤 기능을 수행합니까?',23,0),(172,'도커가 하는 일이 무엇인가요?',23,0),(173,'Docker 서비스는 무슨 작업을 수행합니까?',23,0),(174,'도커 서비스의 주 기능을 알려주세요',23,0),(175,'이 프로젝트의 Docker에 대해 설명해주세요.',23,0),(176,'웹 서비스에 사용한 도커에 대해 가르쳐주세요.',23,0),(177,'Wordpress가 무엇입니까?',24,0),(178,'워드프레스는 무슨 서비스입니까?',24,0),(179,'워드프레스에 대해 알려주십시오.',24,0),(180,'이 프로젝트에서 사용한 워드프레스가 무엇인가요?',24,0),(181,'웹 개발에 쓴 Wordpress는 무엇인가요?',24,0),(182,'Wordpress는 무슨 웹 서비스 기능인가요?',24,0),(183,'Wordpress에 대해 가르쳐주시면 감사하겠습니다.',24,0),(184,'이 프로젝트의 WordPress에 대해 설명해주세요.',24,0),(185,'WordPress의 REST API에 대해 가르쳐주세요.',25,0),(186,'WordPress의 REST API가 무엇인가요?',25,0),(187,'REST API랑 워드프레스를 써서 무엇을 하나요?',25,0),(188,'워드프레스를 통한 REST API는 무엇에 쓰나요?',25,0),(189,'REST API를 통해 Wordpress는 무엇을 하나요?',25,0),(190,'Rest API와 WordPress로 어떤 것을 할 수 있나요?',25,0),(191,'Rest API와 워드프레스로 무엇을 할 수 있습니까?',25,0);
/*!40000 ALTER TABLE `q_list` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2019-11-03 17:47:06
